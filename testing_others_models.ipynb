{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import random\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "from typing import List\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import Wav2Vec2ForSequenceClassification, Wav2Vec2Processor\n",
    "\n",
    "from torchvision.models import resnet18, resnet34, resnet50, densenet121, densenet169\n",
    "from transformers import AutoModelForSequenceClassification, Wav2Vec2ForSequenceClassification\n",
    "\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "import os\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import torchaudio\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained Wav2Vec model\n",
    "wav2vec_model = Wav2Vec2ForSequenceClassification.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "\n",
    "# Modify the classifier head for your classification task\n",
    "num_labels = 50  # Replace with the number of classes in your dataset\n",
    "wav2vec_model.classifier = nn.Linear(wav2vec_model.config.hidden_size, num_labels)\n",
    "\n",
    "# Move the model to the desired device (e.g., GPU)\n",
    "wav2vec_model = wav2vec_model.to(device, non_blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the pre-trained BEATs model\n",
    "beats_model = AutoModelForSequenceClassification.from_pretrained(\"beomi/kcbert-base\")\n",
    "\n",
    "# Modify the classifier head for your classification task\n",
    "num_labels = 50  # Replace with the number of classes in your dataset\n",
    "beats_model.classifier = nn.Linear(beats_model.config.hidden_size, num_labels)\n",
    "\n",
    "# Move the model to the desired device (e.g., GPU)\n",
    "beats_model = beats_model.to(device, non_blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ESC50DataWav2Vec(Dataset):\n",
    "    def __init__(self, base, df, in_col, out_col):\n",
    "        self.df = df\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        self.c2i = {}\n",
    "        self.i2c = {}\n",
    "        self.categories = sorted(df[out_col].unique())\n",
    "        for i, category in enumerate(self.categories):\n",
    "            self.c2i[category] = i\n",
    "            self.i2c[i] = category\n",
    "        for ind in tqdm(range(len(df))):\n",
    "            row = df.iloc[ind]\n",
    "            file_path = os.path.join(base, row[in_col])\n",
    "            waveform, sample_rate = torchaudio.load(file_path)\n",
    "            self.data.append(waveform)\n",
    "            self.labels.append(self.c2i[row['category']])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        waveform = self.data[idx]\n",
    "        waveform = waveform.float()  # Convert waveform to float tensor\n",
    "        label = self.labels[idx]\n",
    "        return waveform, label\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/almogk/ESC-50-master/meta/esc50.csv')\n",
    "\n",
    "train = df[df['fold']!=5]\n",
    "valid = df[df['fold']==5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/almogk/ESC-50-master/meta/esc50.csv')\n",
    "\n",
    "train = df[df['fold']!=5]\n",
    "valid = df[df['fold']==5]\n",
    "\n",
    "train_data = ESC50DataWav2Vec('/home/almogk/ESC-50-master/audio', train, 'filename', 'category')\n",
    "valid_data = ESC50DataWav2Vec('/home/almogk/ESC-50-master/audio', valid, 'filename', 'category')\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=20, shuffle=True)\n",
    "valid_loader = DataLoader(valid_data, batch_size=20, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ESC50Data(Dataset):\n",
    "    def __init__(self, base, df, in_col, out_col):\n",
    "        self.df = df\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        self.c2i={}\n",
    "        self.i2c={}\n",
    "        self.categories = sorted(df[out_col].unique())\n",
    "        for i, category in enumerate(self.categories):\n",
    "            self.c2i[category]=i\n",
    "            self.i2c[i]=category\n",
    "        for ind in tqdm(range(len(df))):\n",
    "            row = df.iloc[ind]\n",
    "            file_path = os.path.join(base, row[in_col])\n",
    "            self.data.append(self.spec_to_image(self.get_melspectrogram_db(file_path))[np.newaxis,...])\n",
    "            self.labels.append(self.c2i[row['category']])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "    \n",
    "    def spec_to_image(self, spec, eps=1e-6):\n",
    "        mean = spec.mean() # -6.6268077\n",
    "        std = spec.std() # 5.358466\n",
    "        spec_norm = (spec - mean) / (std + eps)\n",
    "        spec_min, spec_max = spec_norm.min(), spec_norm.max()\n",
    "        spec_scaled = 255 * (spec_norm - spec_min) / (spec_max - spec_min)\n",
    "        spec_scaled = spec_scaled.astype(np.uint8)\n",
    "        return spec_scaled\n",
    "    \n",
    "    def get_melspectrogram_db(self, file_path, sr=None, n_fft=2048, hop_length=512, n_mels=128, fmin=24, fmax=8300, top_db=80):\n",
    "        wav, sr = librosa.load(file_path,sr=sr)\n",
    "        if wav.shape[0]<5*sr:\n",
    "            wav=np.pad(wav,int(np.ceil((5*sr-wav.shape[0])/2)),mode='reflect')\n",
    "        else:\n",
    "            wav=wav[:5*sr]\n",
    "\n",
    "        spec=librosa.feature.melspectrogram(wav, sr=sr, n_fft=n_fft, hop_length=hop_length,n_mels=n_mels,fmin=fmin,fmax=fmax)\n",
    "        spec_db=librosa.power_to_db(spec,top_db=top_db)\n",
    "        return spec_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/almogk/ESC-50-master/meta/esc50.csv')\n",
    "\n",
    "train = df[df['fold']!=5]\n",
    "valid = df[df['fold']==5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = ESC50Data('/home/almogk/ESC-50-master/audio', train, 'filename', 'category')\n",
    "valid_data = ESC50Data('/home/almogk/ESC-50-master/audio', valid, 'filename', 'category')\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=20, shuffle=True)\n",
    "valid_loader = DataLoader(valid_data, batch_size=20, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet_model_121 = densenet121(pretrained=True)\n",
    "num_ftrs = densenet_model_121.classifier.in_features\n",
    "densenet_model_121.classifier = nn.Linear(num_ftrs, 50)\n",
    "densenet_model_121.features.conv0 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "densenet_model_121 = densenet_model_121.to(device, non_blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet_model_169 = densenet169(pretrained=True)\n",
    "num_ftrs = densenet_model_169.classifier.in_features\n",
    "densenet_model_169.classifier = nn.Linear(num_ftrs, 50)\n",
    "densenet_model_169.features.conv0 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "densenet_model_169 = densenet_model_169.to(device, non_blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model_18 = resnet18(pretrained=True)\n",
    "num_ftrs = resnet_model_18.fc.in_features\n",
    "resnet_model_18.fc = nn.Linear(num_ftrs, 50)\n",
    "resnet_model_18.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "resnet_model_18 = resnet_model_18.to(device, non_blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model_34 = resnet34(pretrained=True)\n",
    "resnet_model_34.fc = nn.Linear(512,50)\n",
    "resnet_model_34.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "resnet_model_34 = resnet_model_34.to(device, non_blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model_50 = resnet50(pretrained=True)\n",
    "num_ftrs = resnet_model_50.fc.in_features\n",
    "resnet_model_50.fc = nn.Linear(num_ftrs, 50)\n",
    "resnet_model_50.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "resnet_model_50 = resnet_model_50.to(device, non_blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loss_fn, train_loader, valid_loader, epochs, optimizer, learning_rate, train_losses, valid_losses, device, change_lr=None):\n",
    "    print('running on ' + str(device))\n",
    "    torch.set_grad_enabled(True)\n",
    "    \n",
    "    scaler = GradScaler()\n",
    "    \n",
    "    for epoch in tqdm(range(1, epochs+1)):\n",
    "        model.train()\n",
    "        batch_losses=[]\n",
    "        if change_lr:\n",
    "            optimizer = change_lr(optimizer, epoch, learning_rate)\n",
    "            for i, data in enumerate(train_loader):\n",
    "                x, y = data\n",
    "                optimizer.zero_grad()\n",
    "                x = x.to(device, dtype=torch.float32)\n",
    "                y = y.to(device, dtype=torch.long)\n",
    "                \n",
    "                \n",
    "                with autocast():\n",
    "                    y_hat = model(x)\n",
    "                    loss = loss_fn(y_hat, y)\n",
    "        \n",
    "                # loss.backward()\n",
    "                scaler.scale(loss).backward()\n",
    "        \n",
    "                batch_losses.append(loss.item())\n",
    "                # optimizer.step()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "        train_losses.append(batch_losses)\n",
    "        print(f'Epoch - {epoch} Train-Loss : {np.mean(train_losses[-1])}')\n",
    "        model.eval()\n",
    "        batch_losses=[]\n",
    "        trace_y = []\n",
    "        trace_yhat = []\n",
    "        for i, data in enumerate(valid_loader):\n",
    "            x, y = data\n",
    "            x = x.to(device, dtype=torch.float32)\n",
    "            y = y.to(device, dtype=torch.long)\n",
    "            \n",
    "            y_hat = model(x)\n",
    "            loss = loss_fn(y_hat, y)\n",
    "            trace_y.append(y.cpu().detach().numpy())\n",
    "            trace_yhat.append(y_hat.cpu().detach().numpy())      \n",
    "            batch_losses.append(loss.item())\n",
    "        valid_losses.append(batch_losses)\n",
    "        trace_y = np.concatenate(trace_y)\n",
    "        trace_yhat = np.concatenate(trace_yhat)\n",
    "        accuracy = np.mean(trace_yhat.argmax(axis=1)==trace_y)\n",
    "        print(f'Epoch - {epoch} Valid-Loss : {np.mean(valid_losses[-1])} Valid-Accuracy : {accuracy}')\n",
    "        # scheduler.step()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setlr(optimizer, lr):\n",
    "  for param_group in optimizer.param_groups:\n",
    "    param_group['lr'] = lr\n",
    "  return optimizer\n",
    "\n",
    "def lr_decay(optimizer, epoch, learning_rate):\n",
    "  if epoch%5==0:\n",
    "    new_lr = learning_rate / (5**(epoch//5))\n",
    "    optimizer = setlr(optimizer, new_lr)\n",
    "    print(f'Changed learning rate to {new_lr}')\n",
    "  return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "learning_rate = 1e-5\n",
    "trainables = [p for p in wav2vec_model.parameters() if p.requires_grad]\n",
    "print('Total parameter number is : {:.3f} million'.format(sum(p.numel() for p in wav2vec_model.parameters()) / 1e6))\n",
    "print('Total trainable parameter number is : {:.3f} million'.format(sum(p.numel() for p in trainables) / 1e6))\n",
    "optimizer = torch.optim.Adam(trainables, learning_rate, weight_decay=5e-6, betas=(0.95, 0.999))\n",
    "\n",
    "epochs = 50\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "resnet_train_losses=[]\n",
    "resnet_valid_losses=[]\n",
    "\n",
    "train(wav2vec_model, loss_fn, train_loader, valid_loader, epochs, optimizer, learning_rate, resnet_train_losses, resnet_valid_losses, device, lr_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "trainables = [p for p in beats_model.parameters() if p.requires_grad]\n",
    "print('Total parameter number is : {:.3f} million'.format(sum(p.numel() for p in beats_model.parameters()) / 1e6))\n",
    "print('Total trainable parameter number is : {:.3f} million'.format(sum(p.numel() for p in trainables) / 1e6))\n",
    "optimizer = torch.optim.Adam(trainables, learning_rate, weight_decay=5e-7, betas=(0.95, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "resnet_train_losses=[]\n",
    "resnet_valid_losses=[]\n",
    "\n",
    "train(beats_model, loss_fn, train_loader, valid_loader, epochs, optimizer, learning_rate, resnet_train_losses, resnet_valid_losses, device, lr_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "trainables = [p for p in resnet_model_34.parameters() if p.requires_grad]\n",
    "print('Total parameter number is : {:.3f} million'.format(sum(p.numel() for p in resnet_model_34.parameters()) / 1e6))\n",
    "print('Total trainable parameter number is : {:.3f} million'.format(sum(p.numel() for p in trainables) / 1e6))\n",
    "optimizer = torch.optim.Adam(trainables, learning_rate, weight_decay=5e-7, betas=(0.95, 0.999))\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, list(range(2, 1000, 5)),gamma=0.85)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "resnet_train_losses=[]\n",
    "resnet_valid_losses=[]\n",
    "\n",
    "train(resnet_model_34, loss_fn, train_loader, valid_loader, epochs, optimizer, learning_rate, resnet_train_losses, resnet_valid_losses, device, lr_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet_model_169\n",
    "\n",
    "learning_rate = 1e-5\n",
    "trainables = [p for p in densenet_model_169.parameters() if p.requires_grad]\n",
    "print('Total parameter number is : {:.3f} million'.format(sum(p.numel() for p in densenet_model_169.parameters()) / 1e6))\n",
    "print('Total trainable parameter number is : {:.3f} million'.format(sum(p.numel() for p in trainables) / 1e6))\n",
    "optimizer = torch.optim.Adam(trainables, learning_rate, weight_decay=5e-6, betas=(0.95, 0.999))\n",
    "\n",
    "epochs = 50\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "resnet_train_losses=[]\n",
    "resnet_valid_losses=[]\n",
    "\n",
    "train(densenet_model_169, loss_fn, train_loader, valid_loader, epochs, optimizer, learning_rate, resnet_train_losses, resnet_valid_losses, device, lr_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-5\n",
    "trainables = [p for p in densenet_model_121.parameters() if p.requires_grad]\n",
    "print('Total parameter number is : {:.3f} million'.format(sum(p.numel() for p in densenet_model_121.parameters()) / 1e6))\n",
    "print('Total trainable parameter number is : {:.3f} million'.format(sum(p.numel() for p in trainables) / 1e6))\n",
    "optimizer = torch.optim.Adam(trainables, learning_rate, weight_decay=5e-6, betas=(0.95, 0.999))\n",
    "\n",
    "epochs = 50\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "resnet_train_losses=[]\n",
    "resnet_valid_losses=[]\n",
    "\n",
    "train(densenet_model_121, loss_fn, train_loader, valid_loader, epochs, optimizer, learning_rate, resnet_train_losses, resnet_valid_losses, device, lr_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "trainables = [p for p in resnet_model_18.parameters() if p.requires_grad]\n",
    "print('Total parameter number is : {:.3f} million'.format(sum(p.numel() for p in resnet_model_18.parameters()) / 1e6))\n",
    "print('Total trainable parameter number is : {:.3f} million'.format(sum(p.numel() for p in trainables) / 1e6))\n",
    "optimizer = torch.optim.Adam(trainables, learning_rate, weight_decay=5e-6, betas=(0.95, 0.999))\n",
    "\n",
    "epochs = 50\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "resnet_train_losses=[]\n",
    "resnet_valid_losses=[]\n",
    "\n",
    "train(resnet_model_18, loss_fn, train_loader, valid_loader, epochs, optimizer, learning_rate, resnet_train_losses, resnet_valid_losses, device, lr_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "trainables = [p for p in resnet_model_50.parameters() if p.requires_grad]\n",
    "print('Total parameter number is : {:.3f} million'.format(sum(p.numel() for p in resnet_model_50.parameters()) / 1e6))\n",
    "print('Total trainable parameter number is : {:.3f} million'.format(sum(p.numel() for p in trainables) / 1e6))\n",
    "optimizer = torch.optim.Adam(trainables, learning_rate, weight_decay=5e-6, betas=(0.95, 0.999))\n",
    "\n",
    "epochs = 50\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "resnet_train_losses=[]\n",
    "resnet_valid_losses=[]\n",
    "\n",
    "train(resnet_model_50, loss_fn, train_loader, valid_loader, epochs, optimizer, learning_rate, resnet_train_losses, resnet_valid_losses, device, lr_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl = np.asarray(resnet_train_losses).ravel()\n",
    "vl = np.asarray(resnet_valid_losses).ravel()\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(tl)\n",
    "plt.legend(['Train Loss'])\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(vl,'orange')\n",
    "plt.legend(['Valid Loss'])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
